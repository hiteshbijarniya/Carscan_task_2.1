{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbfdvT3BrUsn",
        "outputId": "94346a78-368b-4300-e0c4-7d86af4f1205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.63.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "BIjQWuBAsmNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c77a42a1-75a7-400a-e991-7b2565b325a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "qKCxqhuqstxJ"
      },
      "outputs": [],
      "source": [
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEwHhNKDszc4",
        "outputId": "fc973ea8-2a90-4f1b-f046-efd67ce2cbd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "car-damage-detection.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "! kaggle datasets download anujms/car-damage-detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3blG-aRJs2bC",
        "outputId": "6232f9ac-203c-400a-cfbd-a25db3ec1a78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  car-damage-detection.zip\n",
            "replace data1a/training/00-damage/0001.JPEG? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "! unzip car-damage-detection.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "0gfVo6dNs-Vg"
      },
      "outputs": [],
      "source": [
        "#importing librabries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "qRlFvMEKtDCC"
      },
      "outputs": [],
      "source": [
        "#defining the base, train and validation directory path\n",
        "base_dir = 'data1a'\n",
        "train_dir = os.path.join(base_dir, 'training')\n",
        "validation_dir = os.path.join(base_dir, 'validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "YvZPFZhFtGyB"
      },
      "outputs": [],
      "source": [
        "#defining the damage and whole , train nand validation directory\n",
        "train_damage_dir = os.path.join(train_dir, '00-damage')\n",
        "train_whole_dir = os.path.join(train_dir, '01-whole')\n",
        "validation_damage_dir = os.path.join(validation_dir, '00-damage')\n",
        "validation_whole_dir = os.path.join(validation_dir, '01-whole')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2dxvYCvtJjc"
      },
      "source": [
        "Data Augmentation is used to:\n",
        "\n",
        "(a) Rescale the data\n",
        "(b) to bring all the image to same dimension "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "bCIgDZLDtSsM"
      },
      "outputs": [],
      "source": [
        "#data augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5OF5OQUtVZA",
        "outputId": "76438eaf-46ca-42d0-d1e0-8866a2e6dc54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1840 images belonging to 2 classes.\n",
            "Found 460 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,  \n",
        "        target_size=(150, 150), \n",
        "        batch_size=16,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=16,\n",
        "        class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "# Convolutional layer and maxpool layer 1\n",
        "model.add(keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "\n",
        "# Convolutional layer and maxpool layer 2\n",
        "model.add(keras.layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "\n",
        "# Convolutional layer and maxpool layer 3\n",
        "model.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "\n",
        "# Convolutional layer and maxpool layer 4\n",
        "model.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "\n",
        "# This layer flattens the resulting image array to 1D array\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "# Hidden layer with 512 neurons and Rectified Linear Unit activation function \n",
        "model.add(keras.layers.Dense(512,activation='relu'))\n",
        "\n",
        "# Output layer with single neuron which gives 0 for Cat or 1 for Dog \n",
        "#Here we use sigmoid activation function which makes our model output to lie between 0 and 1\n",
        "model.add(keras.layers.Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "w8PnsgGKZNvo"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "FoJR6bvoap_P"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#steps_per_epoch = train_imagesize/batch_size\n",
        "#fit data \n",
        "model.fit_generator(train_generator,\n",
        "         steps_per_epoch = 115,\n",
        "         epochs = 16,\n",
        "         validation_data = validation_generator\n",
        "       )"
      ],
      "metadata": {
        "id": "dg2qGjQzZP8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb07e1d9-c152-49b2-b6b7-4e7bee1895f4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115/115 [==============================] - 17s 133ms/step - loss: 0.6672 - accuracy: 0.5924 - val_loss: 0.6247 - val_accuracy: 0.6804\n",
            "Epoch 2/16\n",
            "115/115 [==============================] - 12s 106ms/step - loss: 0.5960 - accuracy: 0.6957 - val_loss: 0.5539 - val_accuracy: 0.7196\n",
            "Epoch 3/16\n",
            "115/115 [==============================] - 12s 107ms/step - loss: 0.5518 - accuracy: 0.7092 - val_loss: 0.5309 - val_accuracy: 0.7543\n",
            "Epoch 4/16\n",
            "115/115 [==============================] - 12s 106ms/step - loss: 0.5044 - accuracy: 0.7620 - val_loss: 0.5382 - val_accuracy: 0.7435\n",
            "Epoch 5/16\n",
            "115/115 [==============================] - 12s 106ms/step - loss: 0.4404 - accuracy: 0.8016 - val_loss: 0.4781 - val_accuracy: 0.7739\n",
            "Epoch 6/16\n",
            "115/115 [==============================] - 13s 109ms/step - loss: 0.3996 - accuracy: 0.8234 - val_loss: 0.4888 - val_accuracy: 0.7543\n",
            "Epoch 7/16\n",
            "115/115 [==============================] - 12s 107ms/step - loss: 0.3294 - accuracy: 0.8538 - val_loss: 0.5267 - val_accuracy: 0.7826\n",
            "Epoch 8/16\n",
            "115/115 [==============================] - 13s 106ms/step - loss: 0.2623 - accuracy: 0.8908 - val_loss: 0.5585 - val_accuracy: 0.7826\n",
            "Epoch 9/16\n",
            "115/115 [==============================] - 13s 109ms/step - loss: 0.1819 - accuracy: 0.9310 - val_loss: 0.7079 - val_accuracy: 0.7826\n",
            "Epoch 10/16\n",
            "115/115 [==============================] - 12s 108ms/step - loss: 0.1451 - accuracy: 0.9500 - val_loss: 0.6504 - val_accuracy: 0.7957\n",
            "Epoch 11/16\n",
            "115/115 [==============================] - 13s 109ms/step - loss: 0.0795 - accuracy: 0.9739 - val_loss: 0.8289 - val_accuracy: 0.7870\n",
            "Epoch 12/16\n",
            "115/115 [==============================] - 13s 108ms/step - loss: 0.0415 - accuracy: 0.9880 - val_loss: 0.9177 - val_accuracy: 0.7870\n",
            "Epoch 13/16\n",
            "115/115 [==============================] - 13s 109ms/step - loss: 0.0466 - accuracy: 0.9837 - val_loss: 0.9473 - val_accuracy: 0.7761\n",
            "Epoch 14/16\n",
            "115/115 [==============================] - 12s 109ms/step - loss: 0.0494 - accuracy: 0.9821 - val_loss: 1.1010 - val_accuracy: 0.7674\n",
            "Epoch 15/16\n",
            "115/115 [==============================] - 12s 108ms/step - loss: 0.0367 - accuracy: 0.9859 - val_loss: 1.0982 - val_accuracy: 0.7848\n",
            "Epoch 16/16\n",
            "115/115 [==============================] - 12s 107ms/step - loss: 0.0299 - accuracy: 0.9913 - val_loss: 1.1257 - val_accuracy: 0.7913\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe360850050>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "uCebL1-Uwr4J"
      },
      "outputs": [],
      "source": [
        "#weights saving\n",
        "model.save(\"classifier.h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "assign 2.1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}